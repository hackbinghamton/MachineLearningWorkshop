{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### What You'll Learn\n",
    "In this section, you'll learn\n",
    "1. How to find and explore a dataset\n",
    "2. How to create training and testing sets, as well as to show why you need both\n",
    "3. How to use scikit-learn to implement Linear Regression and Logistic Regression models\n",
    "\n",
    "### Prerequisites\n",
    "Before starting this section, you should have an understanding of\n",
    "1. [Basic Python (functions, loops, lists)](https://github.com/HackBinghamton/PythonWorkshop)\n",
    "2. (Optional) [Matplotlib and numpy](https://github.com/HackBinghamton/DataScienceWorkshop)\n",
    "\n",
    "### Introduction\n",
    "**scikit-learn** is a Python machine learning library that allows us to easily implement various machine learning algorithms. Different ML algorithms are good at different things. There is no such thing as a one-size-fits-all ML algorithm. That's why picking the algorithm that you're applying is so important. \n",
    "\n",
    "### Initial Setup Commands\n",
    "**PLEASE run the below code block, or else this workshop won't work properly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Dataset\n",
    "The first step to developing a good machine learning algorithm is using a good dataset. Many of the most accurate machine learning algorithms have millions, if not billions of entries in their training data sets. Fortuntately for us, there already exists many small yet robust datasets we can use to build our ML algorithms. \n",
    "\n",
    "The scikit-learn library comes with some good starting datasets. For today's activity, we'll be recognizing handwritten numbers from scikit-learn's `digits` dataset. This dataset contains over 1700 labeled 8x8 pixel images of hand-drawn numerical digits.\n",
    "\n",
    "To use this dataset, we'll import the `load_digits` function from `sklearn.datasets` and store it in a variable called `digits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exploring a Dataset\n",
    "To get a better sense of what we're working with, let's take a look at the attributes of `digits`. If we add the following line to our code, we can see that the digits dataset has 5 attributes - `DESCR`, `data`, `images`, `target`, and `target_names`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know even more about the dataset, we can print the description of `digits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get the pixel values of each image in `digits`, where each image is represented by a one-dimensional array, we can use `digits.data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(digits.data)\n",
    "print(digits.data.shape)  \n",
    "# NOTE: .shape is used to show the dimensions of the current data. In this case, digits is a two dimensional array \n",
    "# that has 1797 rows (1 for each image in digits) and 64 columns (1 for each pixel in an 8x8 image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`digits.images` also contains each image in `digits`, but each image is represented by an 8x8 array, making `digits.images` a three-dimensional array. Logistic Regression only works with two-dimensional input data, so we will **not** use this attribute for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(digits.images)\n",
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`digits.target` contains the corresponding classification values for each image in `digits.data` (or `digits.image`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`digits.target_names` contains all the possible classification values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the matplotlib library to display the images in this dataset. Add the following code to your script to display the first image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) # Change the number here to look at different images\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes well, you will see the following image appear on your screen -\n",
    "\n",
    "![matplotlib result](images/part1_matplotlib_image.png)\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Further Reading\n",
    "You can find other useful datasets in the [official scikit-learn documentation](https://scikit-learn.org/stable/datasets/index.html). Section 6.2 covers how to load in other datasets such as the Boston Housing Price dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Creating Training and Testing Sets\n",
    "\n",
    "\n",
    "Now, we're going to split the data into two sets: a training set and a testing set. The training set will be used to train the machine learning algorithms, whereas the testing set will be used to verify the accuracy of the machine learning algorithms. \n",
    "\n",
    "\n",
    "To better visualize this relationship, think of a time where you studied for a math exam by completing practice problems, and tested your knowledge by completing the exam. The practice problems you completed were your training set, and the real exam was the testing set. \n",
    "\n",
    "Thankfully, scikit-learn gives us a method for automatically splitting up our full dataset into smaller training and testing sets.\n",
    "\n",
    "âš  **It is imperative that you keep your training and testing sets separate during the training process.** If your machine learning algorithm is tested with a data point it's already seen before, it may report a testing accuracy that is higher than it actually is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, \n",
    "                                                    digits.target, \n",
    "                                                    test_size=0.50, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we pass the following information to the `train_test_split` method from scikit-learn's `model_selection` sublibrary:\n",
    "* `digits.data`: The image data for each image in the `digits` dataset. Each image is a 64-bit array, where each item is either 0 or 1.\n",
    "* `digits.target`: The classification data for each image in the `digits` dataset. In other words, this contains the actual digit the image represents.\n",
    "* `test_size=0.50`: 50% of the images in the `digits` dataset should be used for the testing set. This means that the other 50% will be used for the training set.\n",
    "* `random_state=42`: Seeds the random value with 42. Machine learning algorithms have a degree of randomness, which we mitigate by using the same random seed. Without a constant random seed, our model would have a slightly different accuracy on every run. A constant random seed is useful when building machine learning models because if we improve the model's accuracy, we can be confident that the improved accuracy was due to our improvement and not just statistical variance.\n",
    "  * There is no significance to the number 42 in the context of this program. It's just a pleasant number.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "`train_test_split` then divides it into the following arrays:\n",
    "* `X_train`, a two-dimensional array containing a certain amount of entries from the main dataset. \n",
    "  * Does not include the expected outcome of each data entry.\n",
    "* `Y_train`, a one-dimensional array containing the expected outcome of each data entry in `X_train`.\n",
    "* `X_test`, a two-dimensional array containing a certain amount of entries from the main dataset. \n",
    "  * Does not include the expected outcome of each data entry.\n",
    "* `Y_test`, a one-dimensional array containing the expected outcome of each data entry in `X_test`.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Continuing our analogy of studying for a math exam, \n",
    "* `X_train` contains all your answers to the practice problems\n",
    "* `Y_train` contains all the correct answers to the practice problems\n",
    "* `X_test` contains all your answers to the real exam\n",
    "* `Y_test` contains all the correct answers to the real exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Food for Thought \n",
    "It can be tough to find a good ratio between the training and testing set size. In this case, we split it evenly (`test_size=0.5`), but many algorithms use much smaller testing set sizes (closer to 0.2). Although it may be tempting to improve your algorithm's accuracy by increasing the size of the training set, also consider that this will increase testing accuracy's margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Using a Machine Learning Algorithm\n",
    "Let's get to the fun part, using these algorithms!\n",
    "For now, we'll start off with two regression-based algorithms for supervised learning: Linear Regression and Logistic Regression.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "We'll start by importing both algorithms from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is one of the gold standards in machine learning algorithms. It's very simple, powerful, and easy to interpret. You can think of it as trying to draw a line of best fit in your data like so:\n",
    "\n",
    "![Linear Regression](images/line-of-best-fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a Linear Regression model with `scikit-learn`, we must first initialize a `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit our newly created object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "linear_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are cases where drawing a simple line of best fit just won't help. That's where\n",
    "Logistic Regression might come in handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a very simple case, Logistic Regression can kind of be thought as drawing an\n",
    "S-shaped line of best fit. Here's a visualization:\n",
    "\n",
    "![Logistic Regression](images/logit.jpeg)\n",
    "\n",
    "In short, Logistic Regression is generally used for classifying discrete values (e.g. choosing either 1 or 0), whereas\n",
    "Linear Regression is generally used for predicting continuous values (e.g. choosing a decimal between 1 and 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize our `LogisticRegression` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "#\n",
    "# lbfgs is a parameter estimation algorithm. Read more at https://en.wikipedia.org/wiki/Limited-memory_BFGS.\n",
    "#\n",
    "# multi_class=multinomial specifies that our problem has several different classifications. If our\n",
    "# problem had a binary classification (so we were trying to determine if our outcome was strictly 0 or 1), \n",
    "# we would want to do multi_class='ovr' instead. Alternatively, we can also have scikit-learn choose for us\n",
    "# by doing multi_class='auto'.\n",
    "#\n",
    "# max_iter=10000 specifies that it should take no more than 10000 iterations for the logistic model to converge\n",
    "# to a classification.\n",
    "\n",
    "logistic_model = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit it to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "And now to test these algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME\n",
    "\n",
    "# Print a human-friendly format of the scoring accuracies for both algorithms.\n",
    "print(\"Linear Regression accuracy:\", str(linear_model.score(X_test, Y_test) * 100) + \"%\")\n",
    "print(\"Logistic Regression accuracy:\", str(logistic_model.score(X_test, Y_test) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies for both models are calculated by training the models on the training sets, and then calculating how well they perform against the testing sets. If a model has an accuracy of 97%, that means it correctly identified 97% of the testing set's data points.\n",
    "\n",
    "Clearly, logistic regression is a far more suitable algorithm for correctly determining a handwritten number - it achieves a ~96% accuracy while linear regression is hardly better than a coinflip!\n",
    "\n",
    "But can we do better? \n",
    "\n",
    "**Answer:** Yes, with a neural network. \n",
    "\n",
    "\n",
    "## ðŸ“š Further Reading\n",
    "For an exhaustive list of the machine learning algorithms scikit-learn has to offer, check out [this page in their documentation](https://scikit-learn.org/stable/supervised_learning.html). Machine learning algorithms are not one size fits all - different problems require different algorithms. There are many cases where linear regression will outperform logistic regression, for instance, so it's good to understand the various types of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. Using the [list of scikit-learn datasets](https://scikit-learn.org/stable/datasets/index.html), load a dataset of your choice into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement linear and logisitic regression on this dataset. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next section (recommended): [Introduction to Neural Networks with Tensorflow](https://colab.research.google.com/github/HackBinghamton/MachineLearningWorkshop/blob/master/intro_neural_networks_tf.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
